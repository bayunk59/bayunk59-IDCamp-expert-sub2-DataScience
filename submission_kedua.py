# -*- coding: utf-8 -*-
"""Submission Kedua.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kzq6Yr2djudGqWZzXD_2OQEh4mnJztJq

# **Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech**

*   Nama        : Bayun Kurniawan
*   Email       : bayunk59@gmail.com
*   Id Dicoding : Bayun Kurniawan

# **Persiapan**

## Menyiapkan library yang dibutuhkan
"""

!pip install pandas sqlalchemy
from sqlalchemy import create_engine
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import PowerTransformer
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""## Menyiapkan data yang akan digunakan"""

# Loading data

jaya_df = pd.read_csv(
    'https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/students_performance/data.csv',
    delimiter=";")
jaya_df.head(5)

# Cek missing value
jaya_df.isna().sum()

"""Tidak terdapat missing value"""

# Memeriksa tipe data tiap fitur
jaya_df.info()

jaya_df.describe()

"""# **Data Understanding**"""

# Melihat distribusi data pada fitur 'Status'

sns.countplot(x='Status', data=jaya_df)
plt.title("Distribusi Status Mahasiswa")
plt.show()

status_counts = jaya_df['Status'].value_counts()
status_percent = jaya_df['Status'].value_counts(normalize=True) * 100
status_df = pd.DataFrame({'Jumlah': status_counts, 'Persentase (%)': status_percent})
print(status_df)

"""Berdasarkan distribusi di atas, jumlah mahasiswa yang 'Dropout' lumayan banyak, berjumlah 1421 data dengan presentase mencapai 32%"""

# Distribusi fitur numerik
num_features = jaya_df.select_dtypes(include=[np.number])
# Calculate the number of rows and columns for the subplots
num_cols = 3  # Number of columns in the grid
num_rows = int(np.ceil(len(num_features.columns) / num_cols))  # Calculate rows needed

plt.figure(figsize=(15, 30))
for i, column in enumerate(num_features.columns, 1):
    plt.subplot(num_rows, num_cols, i)  # Use calculated rows and columns
    sns.histplot(jaya_df[column], bins=30, kde=True, color='blue')
    plt.title(f'Distribusi {column}')
plt.tight_layout()
plt.show()

#Ubah tipe data
status_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}
jaya_df['status_label'] = jaya_df['Status'].map(status_mapping)

"""Ubah tipe data 'Status' menjadi 'Status_Label' dengan tipe data integer:
* Dropout menjadi 0,
* Enrolled menjadi 1,
* Graduate menjadi 2
"""

jaya_df.info()

# Cek Korelasi fitur numerik

# Korelasi antar fitur
corr_matrix = jaya_df.corr(numeric_only=True)

# Korelasi terhadap label status
target_corr = corr_matrix['status_label'].sort_values(ascending=False)

# Tampilkan top fitur yang berkorelasi
print("Korelasi fitur terhadap status_label:")
print(target_corr)

plt.figure(figsize=(20, 20))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Matriks Korelasi")
plt.tight_layout()
plt.show()

"""Dari sini bisa dilihat ada beberapa nilai korelasi di atas 0,10 yang negatif dan positif.

Nilai positif menunjukkan dia berbanding lurus dengan status Graduate dan nilai negatif menunjukkan dia berbanding lurus dengan status Dropout

**Nilai Positif**

* Curricular_units_2nd_sem_approved               0.624157
* Curricular_units_2nd_sem_grade                  0.566827
* Curricular_units_1st_sem_approved               0.529123
* Curricular_units_1st_sem_grade                  0.485207
* Tuition_fees_up_to_date                         0.409827
* Scholarship_holder                              0.297595
* Curricular_units_2nd_sem_enrolled               0.175847
* Curricular_units_1st_sem_enrolled               0.155974
* Admission_grade                                 0.120889
* Displaced                                       0.113986
* Previous_qualification_grade                    0.103764
* Curricular_units_2nd_sem_evaluations            0.092721
* Application_order                               0.089791
* Daytime_evening_attendance                      0.075107
* Curricular_units_2nd_sem_credited               0.054004
* Curricular_units_1st_sem_credited               0.048150
* Curricular_units_1st_sem_evaluations            0.044362
* GDP                                             0.044135
* Course                                          0.034219

**Nilai Negatif**

* Application_mode                               -0.221747
* Gender                                         -0.229270
* Debtor                                         -0.240999
* Age_at_enrollment                              -0.243438

# **Data Preparation / Preprocessing**
"""

# Buat salinan data
main_df = jaya_df.copy()

# Hapus data yang tidak penting
# Hapus korelasi di bawah 0,1

main_df.drop(columns=["Status", "Marital_status", "Curricular_units_2nd_sem_evaluations", "Application_order", "Daytime_evening_attendance", "Curricular_units_2nd_sem_credited",
                      "Curricular_units_1st_sem_credited", "Curricular_units_1st_sem_evaluations", "GDP", "Course", "Nacionality", "Mothers_qualification", "Fathers_qualification",
                      "Mothers_occupation", "Fathers_occupation", "Curricular_units_1st_sem_without_evaluations", "Curricular_units_2nd_sem_without_evaluations",
                      "Educational_special_needs", "Unemployment_rate", "International", "Inflation_rate", "Previous_qualification"], inplace=True)

main_df.info()

"""Tersisa 16 fitur"""

# Buat instance MinMaxScaler
scaler = MinMaxScaler()

# Normalisasi semua kolom numerik
numeric_columns = main_df.select_dtypes(include=['int64', 'float64']).columns
main_df[numeric_columns] = scaler.fit_transform(main_df[numeric_columns])

# Pisahkan fitur (X) dan target (y)
X = main_df.drop(columns=['status_label'])
y = main_df['status_label']

# Pastikan y_train dan y_test berisi nilai integer (discrete)
y = y.astype(int)

# Split data menjadi set pelatihan dan set uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tampilkan bentuk set pelatihan dan set uji untuk memastikan split
print(f"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}")

"""# **Modelling**"""

# Definisikan setiap klasifikasi secara terpisah
knn = KNeighborsClassifier().fit(X_train, y_train)
dt = DecisionTreeClassifier().fit(X_train, y_train)
rf = RandomForestClassifier().fit(X_train, y_train)
svm = SVC().fit(X_train, y_train)
nb = GaussianNB().fit(X_train, y_train)

print("Model training selesai.")

"""# **Evaluation**"""

models = {
    'KNN': knn,
    'Decision Tree': dt,
    'Random Forest': rf,
    'SVM': svm,
    'Naive Bayes': nb
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\n=== {name} ===")
    print(f"Akurasi: {acc:.4f}")
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    print("Classification Report:")
    print(classification_report(y_test, y_pred))

"""Berdasarkan kelima model yang saya coba, `Random Forest` memiliki nilai akurasi tertinggi dengan presentase 83%"""

feature_names = X.columns if isinstance(X, pd.DataFrame) else main_df.drop(columns=['status_label']).columns
importances = rf.feature_importances_

feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)
feat_imp.head(15).plot(kind='barh')
plt.title('Top 15 Fitur Penting - Random Forest')
plt.gca().invert_yaxis()
plt.show()

"""# **Mengirim dataset ke dalam database**"""

URL = "postgresql://postgres.grothxunibdanexrilwx:#Napoleon007@aws-0-ap-southeast-1.pooler.supabase.com:6543/postgres"

engine = create_engine(URL)
jaya_df.to_sql('Status', engine)

"""# **requirements**"""

!pip freeze > requirements.txt